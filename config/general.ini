# This is a config file with the settings for a specific orthophoto 
# segmentation.

[general]
# The subject that will be segmented -> must be specified in a specific ini file!!!
segment_subject = MUST_OVERRIDE

[email]
smtp_server = ALV-MAIL-P1.DG3.be
from = pieter.roggemans@lv.vlaanderen.be 
to = pieter.roggemans@lv.vlaanderen.be

[train]
# In json format
label_names_burn_values = { "${general:segment_subject}": 255 }

# The batch size to use. Depends on available hardware and model used.
batch_size_fit = 8
batch_size_predict = 20

max_epoch = 1000

# Info about the images used to train on
# Remark: because the training data is quite specific for an image datasource,
#         always specify the train image_layer per subject
image_layer = MUST_OVERRIDE 
image_pixel_width = 512
image_pixel_height = 512
image_pixel_x_size = 0.25
image_pixel_y_size = 0.25

# Image augmentations in json format
image_augmentations = { "fill_mode": "constant",
                        "cval": 0,
                        "rescale": 0.0039215686274509803921568627451,
                        "rotation_range": 359.0,
                        "width_shift_range": 0.05,
                        "height_shift_range": 0.05,
                        "zoom_range": 0.1,
                        "brightness_range": (0.95,1.05)
                    }

# Mask augmentations in json format
# Remark: the number of randomized values must be the same as for the image, 
# otherwise the random augentations of the mask aren't the same as the image!!!
mask_augmentations = {  "fill_mode": "constant",
                        "cval": 0,
                        "rescale": 0.0039215686274509803921568627451,
                        "rotation_range": 359.0,
                        "width_shift_range": 0.05,
                        "height_shift_range": 0.05,
                        "zoom_range": 0.1,
                        "brightness_range": (1,1)
                    }

[predict]
# The batch size to use. Depends on available hardware and model used.
batch_size = 14

# Info about the source images that need to be predicted
image_layer = BEFL_2018
image_pixel_width = 1024
image_pixel_height = 1024
image_pixel_x_size = 0.25
image_pixel_y_size = 0.25
image_pixels_overlap = 128

[model]
# The segmentation architecture to use for the subject
encoder = inceptionresnetv2
decoder = unet
architecture = ${encoder}+${decoder}
nb_channels = 3

# Force to use a model trained on this traindata version (-1 to disable) -> only overrule in local_overrule.ini!
force_model_traindata_version = -1
# When training, resume training on the corrent best existing model -> only overrule in local_overrule.ini!
resume_train = False

[dirs]
# The base dir where the info for all segmentation projects is stored
base_dir = X:\Monitoring\OrthoSeg

# The job dir
job_dir = ${base_dir}\job

# The project directory for this subject
project_dir = ${base_dir}\${general:segment_subject}

# Training dirs in the project
input_labels_dir = ${project_dir}\input_labels
training_dir = ${project_dir}\training

# Log dirs
log_dir = ${project_dir}\log
log_training_dir = ${training_dir}\log

# Model dir
model_dir = ${project_dir}\models

# Output vector dir
output_vector_dir = ${project_dir}\output_vector

# Dir with the images we want predictions for
base_image_dir = \\dg3.be\alp\gistmp\orthoseg\input_images
predict_image_input_subdir = ${predict:image_pixel_width}x${predict:image_pixel_height}_${predict:image_pixels_overlap}pxOverlap
predict_image_input_dir = ${base_image_dir}\${predict:image_layer}\${predict_image_input_subdir}
predict_image_output_basedir = ${predict_image_input_dir}

# Dir with sample images for use during training
# Remark: these samples are meant to check the training quality, so typicaly
#         the train image image datasource is used!!! 
predictsample_image_input_subdir = ${train:image_pixel_width}x${train:image_pixel_height}
predictsample_image_input_dir = ${base_image_dir}\{train:image_layer}_testsample\${predictsample_image_input_subdir}
predictsample_image_output_basedir = ${predictsample_image_input_dir}

[files]
# File path that will be used to save/load the keras model definition
model_json_filepath = ${dirs:model_dir}\${model:architecture}.json

# File paths where the train, validation and test labels will be found
labellocations_path = ${dirs:input_labels_dir}\${general:segment_subject}_labellocations.gpkg
labeldata_path = ${dirs:input_labels_dir}\${general:segment_subject}_labeldata.gpkg

